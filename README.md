# ü©∫ Classificador de Condi√ß√µes M√©dicas por Sintomas (NLP/ML)

## üéØ Objetivo

Construir um modelo de **Machine Learning (ML)** capaz de inferir uma condi√ß√£o m√©dica (r√≥tulo) a partir de uma lista de sintomas em texto (features). O projeto demonstra um fluxo de trabalho completo, desde a vetoriza√ß√£o de texto at√© a serializa√ß√£o do modelo treinado para uso em produ√ß√£o.

## üõ†Ô∏è Tecnologias e Depend√™ncias

O projeto foi desenvolvido em Python e utiliza as seguintes bibliotecas:

* **Pandas:** Para manipula√ß√£o e estrutura√ß√£o dos dados (DataFrame).
* **Scikit-learn:** A principal biblioteca para Machine Learning, utilizada para o vetorizador TF-IDF, o classificador SVM e as m√©tricas de avalia√ß√£o.
* **Joblib:** Utilizada para serializar (salvar) o modelo e o vetorizador em disco, permitindo que sejam carregados posteriormente sem a necessidade de retreinamento.

## üß† Metodologia e Processo (Workflow)

O fluxo de trabalho do classificador √© dividido em quatro etapas principais:

### 1. Pr√©-processamento e Divis√£o
Os dados de sintomas s√£o limpos (transformados em min√∫sculas) e o conjunto de dados √© dividido em **treino** e **teste** para garantir a avalia√ß√£o imparcial do modelo.

### 2. Vetoriza√ß√£o (Feature Engineering)
A principal etapa de Processamento de Linguagem Natural (NLP) √© a convers√£o do texto em um formato num√©rico. Utilizamos a t√©cnica **TF-IDF**.

#### Fundamentos Alg√©bricos e Estat√≠sticos (TF-IDF)
A matriz TF-IDF (Term Frequency-Inverse Document Frequency) representa cada conjunto de sintomas como um vetor. O valor de cada dimens√£o nesse vetor √© um peso que reflete a import√¢ncia de um sintoma (termo $t$) para a condi√ß√£o (documento $d$) em rela√ß√£o a todo o conjunto de dados.

$$\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)$$

Onde:
* $\text{TF}(t, d)$: Frequ√™ncia do termo $t$ no documento $d$ (sintoma na condi√ß√£o).
* $\text{IDF}(t)$: Penaliza termos muito comuns em todos os documentos (sintomas gen√©ricos como "fever").
    $$\text{IDF}(t) = \log\left(\frac{N}{\text{DF}(t)}\right)$$
    ($N$ = n√∫mero total de condi√ß√µes; $\text{DF}(t)$ = n√∫mero de condi√ß√µes que cont√™m o termo $t$).

### 3. Treinamento do Classificador (SVM)
O modelo escolhido √© o **Support Vector Machine (SVM)** com um **kernel linear**, conhecido por seu bom desempenho em espa√ßos vetoriais de alta dimensionalidade (como a matriz TF-IDF).

#### Fundamentos Alg√©bricos (SVM)
O SVM trabalha encontrando o **hiperplano** que melhor separa as classes no espa√ßo vetorial. Para um modelo linear, o hiperplano √© definido pela equa√ß√£o:
$$w \cdot x - b = 0$$
Onde:
* $x$ √© um vetor de entrada (o vetor TF-IDF).
* $w$ √© o vetor normal ao hiperplano.
* $b$ √© o termo de intercepta√ß√£o (bias).
O algoritmo otimiza $w$ e $b$ para **maximizar a margem** entre o hiperplano e os pontos de dados mais pr√≥ximos (vetores de suporte).

### 4. Serializa√ß√£o e Persist√™ncia
Ap√≥s o treinamento, o modelo SVM (`svm_classifier.joblib`) e o vetorizador TF-IDF (`tfidf_vectorizer.joblib`) s√£o salvos. Isso garante que a aplica√ß√£o em produ√ß√£o possa carregar esses arquivos e fazer previs√µes instant√¢neas, sem precisar rodar o processo de treinamento novamente.

## ‚úÖ Resultados (Conjunto de Dados de Exemplo)

A avalia√ß√£o demonstra a prova de conceito do modelo, com separa√ß√£o perfeita das classes no conjunto de teste simulado:

| M√©trica | Flu | Sinusitis |
| :---: | :---: | :---: |
| **Acur√°cia Geral** | **1.00** | |
| **Precis√£o** | 1.00 | 1.00 |
| **Recall** | 1.00 | 1.00 |
| **F1-Score** | 1.00 | 1.00 |

#### Previs√µes em Novos Dados

| Sintomas | Condi√ß√£o Prevista |
| :---: | :---: |
| `'fever body ache'` | **Flu** |
| `'nasal congestion headache'` | **Sinusitis** |

